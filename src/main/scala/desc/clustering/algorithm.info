
聚类算法简述：

1. kmeans聚类：计算平均值进行聚类，聚类结果为k个聚类中心，其中k为建模传入的聚类个数。
2. GMM算法：（Gaussian Mixture Model）高斯混合模型，其算法原理如下：
    首先假设数据服从Mixture Gaussian Distribution，换句话说，数据可以看作是从多个Gaussian Distribution
    中生成的（Gaussian分布（也叫做正态(Normal) 分布）），每个 GMM 由 K 个 Gaussian 分布组成，每个
    Gaussian 称为一个“Component”，这些 Component 线性加成在一起就组成了GMM 的概率密度函数如下:
          K
    p(x)= ∑ πk.N(x;μk,σk)
         k=1
    即是GMM认为数据是从K个高斯函数组合而来的。那么如何用 GMM 来做 clustering 呢？现在有了数据，假定它们是由 GMM 生成出来的，
    那么我们只要根据数据推出 GMM 的概率分布来就可以了，然后GMM的K个Component 实际上就对应K 个cluster了。根据数据来推算概率
    密度通常被称作 density estimation（密度估计） ，特别地，当我们在已知（或假定）了概率密度函数的形式，而要估计其中的参数的过程被称作“参数估计”。大致思路如下：
    现在假设我们有 N 个数据点，并假设它们服从某个分布（记作 p(x) ），现在要确定里面的一些参数的值，例如，在 GMM 中，
    我们就需要确定πk（权重），μk,σk。我们的想法是，找到这样一组参数，它所确定的概率分布生成这些给定数据点的概率最大，
    而这个概率实际上就等于 prod_{i=1}^N p(x_i) ，我们把这个乘积称作似然函数 (Likelihood Function)。通常单个点的概率都很小，许多很小的数
    字相乘起来在计算机里很容易造成浮点数下溢，因此我们通常会对其取对数，把乘积变成加和 sum_{i=1}^N \log p(x_i)，得到 log-likelihood function
     。接下来我们只要将这个函数最大化，亦即找到这样一组参数值，它让似然函数取得最大值，我们就认为这是最合适的参数，这样就完成了参数估计的过程。
  GMM模型输出结果：比如聚类数为3
  weight=0.500000
  mu=[9.099999999999984,9.099999999999984,9.099999999999984]
  sigma=
  0.006666666666831146  0.006666666666831146  0.006666666666831146
  0.006666666666831146  0.006666666666831146  0.006666666666831146
  0.006666666666831146  0.006666666666831146  0.006666666666831146

  weight=0.210064
  mu=[0.10000403125945577,0.10000403125945577,0.10000403125945577]
  sigma=
  0.006666849264591829  0.006666849264591829  0.006666849264591829
  0.006666849264591829  0.006666849264591829  0.006666849264591829
  0.006666849264591829  0.006666849264591829  0.006666849264591829

  weight=0.289936
  mu=[0.09999707927385391,0.09999707927385391,0.09999707927385391]
  sigma=
  0.006666534351081322  0.006666534351081322  0.006666534351081322
  0.006666534351081322  0.006666534351081322  0.006666534351081322
  0.006666534351081322  0.006666534351081322  0.006666534351081322

 预测结果：可以是该条数据的预测标号，也可是该条数据隶属于每个类别的概率（为一个Double数组）。
3.PIC算法：幂迭代聚类，是一种简单且可扩展的图聚类方法，称之为幂迭代聚类（PIC）。在数据归一化的逐对相似矩阵上，
    使用截断的幂迭代，PIC寻找数据集的一个超低维嵌入（低纬空间投影，embedding ），这种嵌入恰好是很有效的聚类指标，
    使它在真实数据集上总是好于广泛使用的谱聚类方法。
    幂迭代聚类和谱聚类一样，也是基于图的聚类技术，都是先把获得的原始数据集抽象为图结构后（顶点，边和三元组等等）才进一步进行分析的。